{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf418065-4ecb-4910-81aa-4955c360f51d",
   "metadata": {},
   "source": [
    "## CEPARCO CUDA Project Group 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b1c9366e-3b6d-49b7-b4c5-fdad30f92d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin:/usr/local/cuda/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2378b59-8214-4eb6-b077-ba02c2cfd38c",
   "metadata": {},
   "source": [
    "# C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e6b7ba44-3988-4cef-8fbf-00724e54758d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_asum.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_asum.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h> //fabsf and cos/sin functions\n",
    "\n",
    "void asum(size_t n, double* a, double* res) {\n",
    "  *res = 0.0;\n",
    "  for (int i=0; i<n;i++)\n",
    "     *res += fabs(a[i]);\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv){\n",
    "   const size_t N = 28;\n",
    "   const size_t ARRAY_SIZE = 1<<N;\n",
    "   const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "   const size_t loope = 10;\n",
    "\n",
    "   double *a, *res;\n",
    "   a = (double*)malloc(ARRAY_BYTES);\n",
    "   res = (double*)malloc(sizeof(double));\n",
    "\n",
    "   clock_t start, end;\n",
    "\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "    a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "   }\n",
    "\n",
    "   *res = 0.0;\n",
    "\n",
    "   asum(ARRAY_SIZE,a,res);\n",
    "\n",
    "   double elapse, time_taken;\n",
    "   elapse = 0.0f;\n",
    "   for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "     asum(ARRAY_SIZE,a,res);\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "   }\n",
    "\n",
    "    printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "    printf(\"Absolute sum of vector size 2^%lu: %lf \\n\",N,*res);\n",
    "\n",
    "\n",
    "  double err_res = 0.0;\n",
    "   for (int i=0; i<ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "   if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "   else\n",
    "        printf(\"No errors encountered\");\n",
    "\n",
    "    free(a);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bcadf0ac-7e29-4e98-b14b-58ff093ff123",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_asum.c -lm -o C_asum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "67511fdc-71e9-44f7-938d-b71ba12b4ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 1075.339200 milliseconds to execute an array size 268435456 \n",
      "Absolute sum of vector size 2^28: 108762865473.985641 \n",
      "No errors encountered"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_asum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08744a15-2db9-4868-8f1d-2d333da9d298",
   "metadata": {},
   "source": [
    "# Grid Stride; no prefetch, no page creation, no mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d1a508ff-83ad-4424-abb9-6f9d8ccee87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum1.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum1.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h> //fabsf and cos/sin functions\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "        atomicAdd(res,fabs(a[i])); //proper summation function for CUDA\n",
    "}\n",
    "\n",
    "int main(){\n",
    "   const size_t N = 28;\n",
    "   const size_t ARRAY_SIZE = 1<<N;\n",
    "   const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "   const size_t loope = 10;\n",
    "\n",
    "   double *a, *res;\n",
    "   cudaMallocManaged(&a, ARRAY_BYTES);\n",
    "   cudaMallocManaged(&res, sizeof(double));\n",
    "\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "    a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "   }\n",
    "\n",
    "   *res = 0.0;\n",
    "\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Double asum\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    *res = 0.0;\n",
    "    asum <<<numBlocks, numThreads>>> (ARRAY_SIZE,a,res);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "  printf(\"Absolute sum of vector size 2^%lu: %lf \\n\",N,*res);\n",
    "\n",
    "  //Since summation is performed by each kernel, there is no \"element by element\" error checking\n",
    "  double err_res = 0.0;\n",
    "   for (int i=0; i<ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "   if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "   else\n",
    "        printf(\"No errors encountered\");\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(res);\n",
    "  return 0;\n",
    "}\n",
    "//In compiling, -arch=sm_60 allows CUDA 6.0 for use of atomicAdd with double* and double parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "81728ddc-38ce-47ec-bad4-fad706ad97a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum1.cu -lm -o CUDA_asum1 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dc33bb5d-c763-4cec-b063-185d98238bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==994913== NVPROF is profiling process 994913, command: ./CUDA_asum1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Absolute sum of vector size 2^28: 108762865473.984207 \n",
      "No errors encountered"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==994913== Profiling application: ./CUDA_asum1\n",
      "==994913== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  6.77430s        10  677.43ms  614.18ms  1.24349s  asum(unsigned long, double*, double*)\n",
      "      API calls:   91.86%  6.77468s        10  677.47ms  614.21ms  1.24352s  cudaDeviceSynchronize\n",
      "                    7.02%  518.04ms         2  259.02ms  215.37us  517.82ms  cudaMallocManaged\n",
      "                    1.10%  80.889ms         2  40.444ms  364.88us  80.524ms  cudaFree\n",
      "                    0.02%  1.4070ms        10  140.70us  87.799us  498.50us  cudaLaunchKernel\n",
      "                    0.00%  237.07us       114  2.0790us     115ns  98.651us  cuDeviceGetAttribute\n",
      "                    0.00%  46.300us         1  46.300us  46.300us  46.300us  cuDeviceGetName\n",
      "                    0.00%  18.234us         1  18.234us  18.234us  18.234us  cuDeviceTotalMem\n",
      "                    0.00%  3.4690us         1  3.4690us  3.4690us  3.4690us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.9570us         3     985ns     110ns  2.6070us  cuDeviceGetCount\n",
      "                    0.00%     712ns         2     356ns     171ns     541ns  cuDeviceGet\n",
      "                    0.00%     431ns         1     431ns     431ns     431ns  cuModuleGetLoadingMode\n",
      "                    0.00%     232ns         1     232ns     232ns     232ns  cuDeviceGetUuid\n",
      "\n",
      "==994913== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "   30928  33.929KB  4.0000KB  0.9961MB  1.000763GB  198.8036ms  Host To Device\n",
      "   12306  170.46KB  4.0000KB  0.9961MB  2.000549GB  213.1260ms  Device To Host\n",
      "    2575         -         -         -           -  751.6967ms  Gpu page fault groups\n",
      "Total CPU Page faults: 12299\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3cbc5-b6d7-4917-a5c6-faa9692b6636",
   "metadata": {},
   "source": [
    "# Grid Stride; with prefetch, no page creation, no mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9950c74c-76bb-4501-b098-da9f1d572d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "        atomicAdd(res,fabs(a[i]));\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "   const size_t N = 28;\n",
    "   const size_t ARRAY_SIZE = 1<<N;\n",
    "   const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "   const size_t loope = 10;\n",
    "\n",
    "   double *a, *res;\n",
    "   cudaMallocManaged(&a, ARRAY_BYTES);\n",
    "   cudaMallocManaged(&res, sizeof(double));\n",
    "\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "    a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "   }\n",
    "\n",
    "   *res = 0.0;\n",
    "\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Double asum\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    *res = 0.0;\n",
    "    asum <<<numBlocks, numThreads>>> (ARRAY_SIZE,a,res);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(res,sizeof(double),cudaCpuDeviceId,NULL);\n",
    "\n",
    "  printf(\"Absolute sum of vector size 2^%lu: %lf \\n\",N,*res);\n",
    "\n",
    "  double err_res = 0.0;\n",
    "   for (int i=0; i<ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "   if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "   else\n",
    "        printf(\"No errors encountered\");\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(res);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "182b8941-d13e-49a8-b915-9acc11fb4dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum2.cu -lm -o CUDA_asum2 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9111de01-ebbf-4a8b-9e65-59dfffc9b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==994972== NVPROF is profiling process 994972, command: ./CUDA_asum2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Absolute sum of vector size 2^28: 108762865473.984070 \n",
      "No errors encountered"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==994972== Profiling application: ./CUDA_asum2\n",
      "==994972== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  6.14741s        10  614.74ms  614.28ms  617.26ms  asum(unsigned long, double*, double*)\n",
      "      API calls:   83.53%  6.14767s        10  614.77ms  614.30ms  617.28ms  cudaDeviceSynchronize\n",
      "                    7.22%  531.54ms         2  265.77ms  432.24us  531.11ms  cudaMallocManaged\n",
      "                    5.93%  436.62ms         3  145.54ms  143.09us  361.12ms  cudaMemPrefetchAsync\n",
      "                    1.68%  123.57ms         2  61.784ms  2.6801ms  120.89ms  cudaFree\n",
      "                    1.63%  119.92ms        10  11.992ms  71.172us  118.89ms  cudaLaunchKernel\n",
      "                    0.00%  233.15us       114  2.0450us     112ns  98.084us  cuDeviceGetAttribute\n",
      "                    0.00%  51.044us         1  51.044us  51.044us  51.044us  cudaGetDevice\n",
      "                    0.00%  35.760us         1  35.760us  35.760us  35.760us  cuDeviceGetName\n",
      "                    0.00%  10.133us         1  10.133us  10.133us  10.133us  cuDeviceTotalMem\n",
      "                    0.00%  3.8100us         3  1.2700us     193ns  3.3210us  cuDeviceGetCount\n",
      "                    0.00%  3.0020us         1  3.0020us  3.0020us  3.0020us  cuDeviceGetPCIBusId\n",
      "                    0.00%     585ns         2     292ns     141ns     444ns  cuDeviceGet\n",
      "                    0.00%     384ns         1     384ns     384ns     384ns  cuModuleGetLoadingMode\n",
      "                    0.00%     206ns         1     206ns     206ns     206ns  cuDeviceGetUuid\n",
      "\n",
      "==994972== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1044  1.9623MB  4.0000KB  2.0000MB  2.000610GB  190.6673ms  Host To Device\n",
      "    1043  1.9641MB  4.0000KB  2.0000MB  2.000553GB  355.1156ms  Device To Host\n",
      "      10         -         -         -           -  6.840858ms  Gpu page fault groups\n",
      "Total CPU Page faults: 6154\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb31e03-22ba-4797-aea8-1fe62a25f3d2",
   "metadata": {},
   "source": [
    "# Grid Stride; with prefetch; with page creation; no mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7bb8fdb9-ea82-4fb9-b58e-89bdc5152619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum3.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "        atomicAdd(res,fabs(a[i]));\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "   const size_t N = 28;\n",
    "   const size_t ARRAY_SIZE = 1<<N;\n",
    "   const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "   const size_t loope = 10;\n",
    "\n",
    "   double *a, *res;\n",
    "   cudaMallocManaged(&a, ARRAY_BYTES);\n",
    "   cudaMallocManaged(&res, sizeof(double));\n",
    "\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(res,sizeof(double),device,NULL);\n",
    "\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "    a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "   }\n",
    "\n",
    "   *res = 0.0;\n",
    "\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Double asum\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    *res = 0.0;\n",
    "    asum <<<numBlocks, numThreads>>> (ARRAY_SIZE,a,res);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(res,sizeof(double),cudaCpuDeviceId,NULL);\n",
    "\n",
    "  printf(\"Absolute sum of vector size 2^%lu: %lf \\n\",N,*res);\n",
    "\n",
    "  double err_res = 0.0;\n",
    "   for (int i=0; i<ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "   if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "   else\n",
    "        printf(\"No errors encountered\");\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(res);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b2e3359d-67eb-4f21-b211-1c1b99325a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum3.cu -lm -o CUDA_asum3 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b7cc9228-f50b-49be-9895-887de9de80b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995030== NVPROF is profiling process 995030, command: ./CUDA_asum3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Absolute sum of vector size 2^28: 108762865473.983566 \n",
      "No errors encountered"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995030== Profiling application: ./CUDA_asum3\n",
      "==995030== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  6.14550s        10  614.55ms  614.42ms  614.73ms  asum(unsigned long, double*, double*)\n",
      "      API calls:   77.62%  6.14508s        10  614.51ms  614.38ms  614.67ms  cudaDeviceSynchronize\n",
      "                   14.50%  1.14826s         5  229.65ms  142.99us  761.50ms  cudaMemPrefetchAsync\n",
      "                    5.46%  432.61ms         2  216.30ms  362.51us  432.24ms  cudaMallocManaged\n",
      "                    1.64%  129.92ms        10  12.992ms  128.76us  128.49ms  cudaLaunchKernel\n",
      "                    0.77%  60.790ms         2  30.395ms  317.65us  60.472ms  cudaFree\n",
      "                    0.00%  361.51us       114  3.1710us     205ns  142.24us  cuDeviceGetAttribute\n",
      "                    0.00%  52.134us         1  52.134us  52.134us  52.134us  cuDeviceGetName\n",
      "                    0.00%  14.554us         1  14.554us  14.554us  14.554us  cuDeviceTotalMem\n",
      "                    0.00%  7.9700us         1  7.9700us  7.9700us  7.9700us  cudaGetDevice\n",
      "                    0.00%  6.3670us         1  6.3670us  6.3670us  6.3670us  cuDeviceGetPCIBusId\n",
      "                    0.00%  4.1530us         3  1.3840us     203ns  3.6120us  cuDeviceGetCount\n",
      "                    0.00%  1.2800us         2     640ns     226ns  1.0540us  cuDeviceGet\n",
      "                    0.00%     564ns         1     564ns     564ns     564ns  cuModuleGetLoadingMode\n",
      "                    0.00%     357ns         1     357ns     357ns     357ns  cuDeviceGetUuid\n",
      "\n",
      "==995030== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1044  1.9623MB  4.0000KB  2.0000MB  2.000610GB  218.5661ms  Host To Device\n",
      "    1044  1.9622MB  4.0000KB  2.0000MB  2.000557GB  287.7889ms  Device To Host\n",
      "      10         -         -         -           -  7.694774ms  Gpu page fault groups\n",
      "Total CPU Page faults: 10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c400a302-948c-4fb3-9176-69e7f3b81fb2",
   "metadata": {},
   "source": [
    "# Grid Stride; with prefetch; with page creation; with mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ac10977b-3b43-401b-8557-10001a78e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum4.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "        atomicAdd(res,fabs(a[i]));\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "   const size_t N = 28;\n",
    "   const size_t ARRAY_SIZE = 1<<N;\n",
    "   const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "   const size_t loope = 10;\n",
    "\n",
    "   double *a, *res;\n",
    "   cudaMallocManaged(&a, ARRAY_BYTES);\n",
    "   cudaMallocManaged(&res, sizeof(double));\n",
    "\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(a, ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(a, ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(res,sizeof(double),device,NULL);\n",
    "\n",
    "// ****init array\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) {\n",
    "    a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "   }\n",
    "\n",
    "   *res = 0.0;\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Double asum\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    *res = 0.0;\n",
    "    asum <<<numBlocks, numThreads>>> (ARRAY_SIZE,a,res);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(a,ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(res,sizeof(double),cudaCpuDeviceId,NULL);\n",
    "\n",
    "  printf(\"Absolute sum of vector size 2^%lu: %lf \\n\",N,*res);\n",
    "\n",
    "  double err_res = 0.0;\n",
    "   for (int i=0; i<ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "   if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "   else\n",
    "        printf(\"No errors encountered\");\n",
    "\n",
    "  cudaFree(a);\n",
    "  cudaFree(res);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7dc45ca7-6eb9-4207-8cb3-45cd076f4cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum4.cu -lm -o CUDA_asum4 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7c6ebb71-1983-4772-bd2c-16173ad5a616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995509== NVPROF is profiling process 995509, command: ./CUDA_asum4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Absolute sum of vector size 2^28: 108762865473.985260 \n",
      "No errors encountered"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995509== Profiling application: ./CUDA_asum4\n",
      "==995509== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  6.14846s        10  614.85ms  614.54ms  616.32ms  asum(unsigned long, double*, double*)\n",
      "      API calls:   78.99%  6.14887s        10  614.89ms  614.56ms  616.35ms  cudaDeviceSynchronize\n",
      "                   14.75%  1.14843s         5  229.69ms  79.875us  910.78ms  cudaMemPrefetchAsync\n",
      "                    5.09%  396.24ms         2  198.12ms  160.53us  396.08ms  cudaMallocManaged\n",
      "                    1.14%  88.835ms         2  44.417ms  217.70us  88.617ms  cudaFree\n",
      "                    0.02%  1.3105ms        10  131.05us  73.616us  486.54us  cudaLaunchKernel\n",
      "                    0.00%  182.42us       114  1.6000us     109ns  77.594us  cuDeviceGetAttribute\n",
      "                    0.00%  82.160us         2  41.080us  10.896us  71.264us  cudaMemAdvise\n",
      "                    0.00%  20.925us         1  20.925us  20.925us  20.925us  cuDeviceGetName\n",
      "                    0.00%  8.8080us         1  8.8080us  8.8080us  8.8080us  cuDeviceTotalMem\n",
      "                    0.00%  3.7810us         1  3.7810us  3.7810us  3.7810us  cudaGetDevice\n",
      "                    0.00%  2.7040us         1  2.7040us  2.7040us  2.7040us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.2940us         3     431ns     118ns     933ns  cuDeviceGetCount\n",
      "                    0.00%     626ns         2     313ns     134ns     492ns  cuDeviceGet\n",
      "                    0.00%     247ns         1     247ns     247ns     247ns  cuDeviceGetUuid\n",
      "                    0.00%     238ns         1     238ns     238ns     238ns  cuModuleGetLoadingMode\n",
      "\n",
      "==995509== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    1044  1.9623MB  4.0000KB  2.0000MB  2.000610GB  224.7083ms  Host To Device\n",
      "      20  29.199KB  4.0000KB  60.000KB  584.0000KB  87.87200us  Device To Host\n",
      "      10         -         -         -           -  8.939301ms  Gpu page fault groups\n",
      "Total CPU Page faults: 10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be1478-ff4f-4856-bea0-8ce50bb5935c",
   "metadata": {},
   "source": [
    "# Classic MemCopy (no Unified Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "46e91650-f6bd-4f36-9bf3-67cc8175b5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum5.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "#include <time.h>\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    double localSum = 0.0;\n",
    "\n",
    "    // Each thread sums part of the array\n",
    "    for (int i = index; i < n; i += stride)\n",
    "        localSum += fabs(a[i]);\n",
    "\n",
    "    // Atomic add partial results to global sum\n",
    "    atomicAdd(res, localSum);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t N = 28;\n",
    "    const size_t ARRAY_SIZE = 1 << N;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "    const size_t loope = 10;\n",
    "\n",
    "    // Allocate host memory (regular malloc)\n",
    "    double *h_a = (double*)malloc(ARRAY_BYTES);\n",
    "    double h_res = 0.0;\n",
    "\n",
    "    // Initialize host data\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++)\n",
    "        h_a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "\n",
    "    // Allocate device memory (no Unified Memory)\n",
    "    double *d_a, *d_res;\n",
    "    cudaMalloc(&d_a, ARRAY_BYTES);\n",
    "    cudaMalloc(&d_res, sizeof(double));\n",
    "\n",
    "    // Copy data to device\n",
    "    cudaMemcpy(d_a, h_a, ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_res, &h_res, sizeof(double), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Kernel setup\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "\n",
    "    printf(\"*** function = Double asum (Classic MemCopy)\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu\\n\", numBlocks, numThreads);\n",
    "\n",
    "    // Run kernel multiple times\n",
    "    double zero = 0.0;\n",
    "    for (size_t i = 0; i < loope; i++) {\n",
    "        cudaMemcpy(d_res, &zero, sizeof(double), cudaMemcpyHostToDevice);\n",
    "        asum<<<numBlocks, numThreads>>>(ARRAY_SIZE, d_a, d_res);\n",
    "        cudaDeviceSynchronize();\n",
    "    }\n",
    "\n",
    "    // Copy result back to host\n",
    "    cudaMemcpy(&h_res, d_res, sizeof(double), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"Absolute sum of vector size 2^%lu: %lf\\n\", N, h_res);\n",
    "\n",
    "    // Validate result\n",
    "    double err_res = 0.0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++)\n",
    "        err_res += fabs(h_a[i]);\n",
    "\n",
    "    if (fabs(err_res - h_res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", h_res, err_res, (err_res - h_res));\n",
    "    else\n",
    "        printf(\"No errors encountered\\n\");\n",
    "\n",
    "    // Free memory\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_res);\n",
    "    free(h_a);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5d33c269-12cf-4fa4-89e0-22b9e87bc45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum5.cu -lm -o CUDA_asum5 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "457efc26-6dda-43f3-b98c-68d37c370d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995143== NVPROF is profiling process 995143, command: ./CUDA_asum5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum (Classic MemCopy)\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024\n",
      "Absolute sum of vector size 2^28: 108762865473.983994\n",
      "No errors encountered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995143== Profiling application: ./CUDA_asum5\n",
      "==995143== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   87.29%  6.13784s        10  613.78ms  613.78ms  613.79ms  asum(unsigned long, double*, double*)\n",
      "                   12.71%  893.55ms        12  74.463ms     640ns  893.54ms  [CUDA memcpy HtoD]\n",
      "                    0.00%  3.0720us         1  3.0720us  3.0720us  3.0720us  [CUDA memcpy DtoH]\n",
      "      API calls:   82.86%  6.13814s        10  613.81ms  613.80ms  613.84ms  cudaDeviceSynchronize\n",
      "                   12.08%  894.85ms        13  68.835ms  10.763us  893.93ms  cudaMemcpy\n",
      "                    5.01%  371.38ms         2  185.69ms  125.90us  371.25ms  cudaMalloc\n",
      "                    0.03%  2.0462ms         2  1.0231ms  112.14us  1.9341ms  cudaFree\n",
      "                    0.02%  1.2104ms        10  121.04us  32.102us  542.35us  cudaLaunchKernel\n",
      "                    0.00%  205.33us       114  1.8010us     117ns  95.307us  cuDeviceGetAttribute\n",
      "                    0.00%  19.441us         1  19.441us  19.441us  19.441us  cuDeviceGetName\n",
      "                    0.00%  9.0200us         1  9.0200us  9.0200us  9.0200us  cuDeviceTotalMem\n",
      "                    0.00%  2.7180us         1  2.7180us  2.7180us  2.7180us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.5650us         3     855ns     281ns  1.9530us  cuDeviceGetCount\n",
      "                    0.00%     561ns         2     280ns     131ns     430ns  cuDeviceGet\n",
      "                    0.00%     283ns         1     283ns     283ns     283ns  cuModuleGetLoadingMode\n",
      "                    0.00%     244ns         1     244ns     244ns     244ns  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3e9143-484d-4af0-801d-9e1a38723006",
   "metadata": {},
   "source": [
    "# Grid-Stride Loop with Prefetch and GPU Data Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8f0e100d-4320-4cc7-b776-1dcdce4de7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_asum6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_asum6.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "\n",
    "__global__\n",
    "void init_array(size_t n, double* a) {\n",
    "    size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    size_t stride = blockDim.x * gridDim.x;\n",
    "    for (size_t i = index; i < n; i += stride) {\n",
    "        a[i] = sin((double)i * 0.0003) * cos((double)i * 0.0007) * 1000.0;\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__\n",
    "void asum(size_t n, double* a, double *res) {\n",
    "    size_t index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    size_t stride = blockDim.x * gridDim.x;\n",
    "    for (size_t i = index; i < n; i += stride)\n",
    "        atomicAdd(res, fabs(a[i]));\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t N = 28;\n",
    "    const size_t ARRAY_SIZE = 1 << N;\n",
    "    const size_t ARRAY_BYTES = ARRAY_SIZE * sizeof(double);\n",
    "    const size_t loope = 10;\n",
    "\n",
    "    double *a, *res;\n",
    "    cudaMallocManaged(&a, ARRAY_BYTES);\n",
    "    cudaMallocManaged(&res, sizeof(double));\n",
    "\n",
    "    int device = -1;\n",
    "    cudaGetDevice(&device);\n",
    "\n",
    "    // Prefetch to GPU before initializing\n",
    "    cudaMemPrefetchAsync(a, ARRAY_BYTES, device, NULL);\n",
    "    cudaMemPrefetchAsync(res, sizeof(double), device, NULL);\n",
    "\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads - 1) / numThreads;\n",
    "\n",
    "    // GPU kernel to initialize array\n",
    "    init_array<<<numBlocks, numThreads>>>(ARRAY_SIZE, a);\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    *res = 0.0;\n",
    "\n",
    "    printf(\"*** function = Double asum (GPU init data)\\n\");\n",
    "    printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "    printf(\"numBlocks = %lu, numThreads = %lu \\n\", numBlocks, numThreads);\n",
    "\n",
    "    for (size_t i=0; i<loope;i++){\n",
    "      *res = 0.0;\n",
    "      asum <<<numBlocks, numThreads>>> (ARRAY_SIZE,a,res);\n",
    "      cudaDeviceSynchronize();\n",
    "    }\n",
    "\n",
    "    // Prefetch back to CPU for validation\n",
    "    cudaMemPrefetchAsync(a, ARRAY_BYTES, cudaCpuDeviceId, NULL);\n",
    "    cudaMemPrefetchAsync(res, sizeof(double), cudaCpuDeviceId, NULL);\n",
    "\n",
    "    printf(\"Absolute sum of vector size 2^%lu: %lf \\n\", N, *res);\n",
    "\n",
    "    // Verify result on CPU\n",
    "    double err_res = 0.0;\n",
    "    for (size_t i = 0; i < ARRAY_SIZE; i++)\n",
    "        err_res += fabs(a[i]);\n",
    "\n",
    "    if (fabs(err_res - *res) > 1e-2)\n",
    "        printf(\"Error encountered: \\n Function result: %lf \\n Error checking result: %lf \\n Error difference: %lf \\n\", *res, err_res, (err_res - *res));\n",
    "    else\n",
    "        printf(\"No errors encountered\\n\");\n",
    "\n",
    "    cudaFree(a);\n",
    "    cudaFree(res);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bbf2f58f-f1cd-4de4-9aba-7c91c1e92b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_asum6.cu -lm -o CUDA_asum6 -Wno-deprecated-gpu-targets -arch=sm_60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "80c7da97-9001-4eca-b85e-48821e5041b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995205== NVPROF is profiling process 995205, command: ./CUDA_asum6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Double asum (GPU init data)\n",
      "numElements = 268435456\n",
      "numBlocks = 262144, numThreads = 1024 \n",
      "Absolute sum of vector size 2^28: 108762865473.984299 \n",
      "No errors encountered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==995205== Profiling application: ./CUDA_asum6\n",
      "==995205== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   99.95%  6.14571s        10  614.57ms  614.30ms  614.71ms  asum(unsigned long, double*, double*)\n",
      "                    0.05%  3.2484ms         1  3.2484ms  3.2484ms  3.2484ms  init_array(unsigned long, double*)\n",
      "      API calls:   80.74%  6.14928s        11  559.03ms  3.2807ms  614.83ms  cudaDeviceSynchronize\n",
      "                   13.41%  1.02105s         4  255.26ms  148.00us  1.00353s  cudaMemPrefetchAsync\n",
      "                    5.00%  380.48ms         2  190.24ms  264.03us  380.22ms  cudaMallocManaged\n",
      "                    0.82%  62.749ms         2  31.374ms  292.64us  62.456ms  cudaFree\n",
      "                    0.03%  2.0772ms        11  188.83us  73.388us  922.05us  cudaLaunchKernel\n",
      "                    0.00%  294.08us       114  2.5790us     119ns  138.29us  cuDeviceGetAttribute\n",
      "                    0.00%  54.384us         1  54.384us  54.384us  54.384us  cuDeviceGetName\n",
      "                    0.00%  11.768us         1  11.768us  11.768us  11.768us  cuDeviceTotalMem\n",
      "                    0.00%  4.8490us         1  4.8490us  4.8490us  4.8490us  cudaGetDevice\n",
      "                    0.00%  3.2330us         1  3.2330us  3.2330us  3.2330us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.6220us         3     874ns     133ns  2.2980us  cuDeviceGetCount\n",
      "                    0.00%     621ns         2     310ns     134ns     487ns  cuDeviceGet\n",
      "                    0.00%     377ns         1     377ns     377ns     377ns  cuModuleGetLoadingMode\n",
      "                    0.00%     219ns         1     219ns     219ns     219ns  cuDeviceGetUuid\n",
      "\n",
      "==995205== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      20  32.000KB  4.0000KB  60.000KB  640.0000KB  121.0870us  Host To Device\n",
      "    1044  1.9622MB  4.0000KB  2.0000MB  2.000557GB  704.5613ms  Device To Host\n",
      "      10         -         -         -           -  7.850324ms  Gpu page fault groups\n",
      "Total CPU Page faults: 10\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_asum6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728ca515-4ce5-4933-9b10-fcad4130013c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708502b-8377-42f9-9c84-db20d5bafca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
